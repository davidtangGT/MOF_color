{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import joblib\n",
    "from descriptornames import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7207c5326f20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mruamel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdescriptornames\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Filename: /home/kevin/Dropbox (LSMO)/proj75_mofcolor/ml/code/utils.py\n",
    "Path: /home/kevin/Dropbox (LSMO)/proj75_mofcolor/ml/code\n",
    "Created Date: Monday, February 24th 2020, 4:42:56 pm\n",
    "Author: Kevin Jablonka\n",
    "\n",
    "Copyright (c) 2020 Kevin Jablonka\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatch\n",
    "from webcolors import rgb_to_hex\n",
    "import matplotlib.pyplot as plt\n",
    "from comet_ml import Experiment\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras import backend as BK\n",
    "import pandas as pd\n",
    "import ruamel.yaml as yaml\n",
    "from .descriptornames import *\n",
    "from numpy.random import seed\n",
    "import joblib\n",
    "\n",
    "\n",
    "def augment_data(\n",
    "    df, augment_dict, r_col=\"r\", g_col=\"g\", b_col=\"b\", name_col=\"color_cleaned\"\n",
    "):\n",
    "    df_ = df.copy()\n",
    "\n",
    "    new_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        color = row[name_col]\n",
    "        r_ = row.copy()\n",
    "        for rgb in augment_dict[color]:\n",
    "            r_[r_col] = rgb[0]\n",
    "            r_[g_col] = rgb[1]\n",
    "            r_[b_col] = rgb[2]\n",
    "            new_rows.append(r_)\n",
    "\n",
    "    new_df = pd.concat([df, pd.DataFrame(new_rows)])\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def augment_random(colorname, augment_dict):\n",
    "    possible_colors = augment_dict[colorname]\n",
    "    chosen_color = random.choice(possible_colors)\n",
    "    return np.array(chosen_color)\n",
    "\n",
    "\n",
    "def tf_augment_random():\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def read_pickle(file):\n",
    "    with open(file, \"rb\") as fh:\n",
    "        result = pickle.load(fh)\n",
    "    return result\n",
    "\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = (\n",
    "        tf.abs(error) < 1\n",
    "    )  # replace `tf` with `K` where `K = keras.backend`\n",
    "    squared_loss = tf.square(error) / 2  # replace `tf` with `K`\n",
    "    linear_loss = tf.abs(error) - 0.5  # replace `tf` with `K`\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "\n",
    "def get_timestamp_string():\n",
    "    t = time.localtime()\n",
    "    timestamp = time.strftime(\"%b-%d-%Y_%H%M\", t)\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "def mapping_to_target_range(x, target_min=0, target_max=1):\n",
    "    \"\"\"Linear activation function that constrains output to a range\n",
    "    \n",
    "    Arguments:\n",
    "        x {tensor} -- input tensor\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        target_min {float} -- minimum output (default: {0})\n",
    "        target_max {float} -- maximum output (default: {1})\n",
    "    \n",
    "    Returns:\n",
    "        tensor -- constrained linear activation\n",
    "    \"\"\"\n",
    "    x02 = x + 1  # x in range(0,2)\n",
    "    scale = (target_max - target_min) / 2.0\n",
    "    return x02 * scale + target_min\n",
    "\n",
    "\n",
    "def mapping_to_target_range_sig(x, target_min=0, target_max=255):\n",
    "    \"\"\"Sigmoid activation function that constrains output to a range\n",
    "    \n",
    "    Arguments:\n",
    "        x {tensor} -- input tensor\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        target_min {float} -- minimum output (default: {0})\n",
    "        target_max {float} -- maximum output (default: {255})\n",
    "    \n",
    "    Returns:\n",
    "        tensor -- constrained Sigmoid activation\n",
    "    \"\"\"\n",
    "    x02 = BK.sigmoid(x) + 1  # x in range(0,2)\n",
    "    scale = (target_max - target_min) / 2.0\n",
    "    return x02 * scale + target_min\n",
    "\n",
    "\n",
    "def plot_predictions(predictions, labels, names, sample=100, outname=None):\n",
    "    \"\"\"Plot figure that compares color of predictions versus acutal colors.\n",
    "    \n",
    "    Arguments:\n",
    "        predictions {iterable} -- iterable of rgb colors\n",
    "        labels {iterable} -- iterable of rgb colors\n",
    "        names {iterable} -- iterable of strings\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        sample {int} -- how many samples to plot (default: {100})\n",
    "        outname {string} -- path to which figure is saved (default: {None})\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=[4.8, 16])\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    predictions = predictions[:sample]\n",
    "    names = names[:sample]\n",
    "    labels = labels[:sample]\n",
    "\n",
    "    predictions = [rgb_to_hex((int(c[0]), int(c[1]), int(c[2]))) for c in predictions]\n",
    "    true = [rgb_to_hex((int(c[0]), int(c[1]), int(c[2]))) for c in labels]\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        r1 = mpatch.Rectangle((0, i), 1, 1, color=predictions[i])\n",
    "        r2 = mpatch.Rectangle((1, i), 1, 1, color=true[i])\n",
    "        txt = ax.text(2, i + 0.5, \"  \" + names[i], va=\"center\", fontsize=10)\n",
    "\n",
    "        ax.add_patch(r1)\n",
    "        ax.add_patch(r2)\n",
    "        ax.axhline(i, color=\"k\")\n",
    "\n",
    "    ax.text(0.5, i + 1.5, \"prediction\", ha=\"center\", va=\"center\")\n",
    "    ax.text(1.5, i + 1.5, \"median RGB for label\", ha=\"center\", va=\"center\")\n",
    "    ax.set_xlim(0, 3)\n",
    "    ax.set_ylim(0, i + 2)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if outname is not None:\n",
    "        fig.savefig(outname, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def flatten(d, parent_key=\"\", sep=\"_\"):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "def parse_config(yml_file):\n",
    "    with open(yml_file, \"r\") as stream:\n",
    "        try:\n",
    "            config = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    return config\n",
    "\n",
    "\n",
    "def make_if_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def select_features(selection: list):\n",
    "    selected_features = []\n",
    "    for feature in selection:\n",
    "        selected_features.extend(descriptor_dict[feature])\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(\"scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/color_feat_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "        df, train_size=0.7, random_state=int(821996)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"metalcenter_descriptors\",\n",
    "    \"functionalgroup_descriptors\",\n",
    "    \"linker_descriptors\",\n",
    "    \"mol_desc\",\n",
    "    \"summed_linker_descriptors\",\n",
    "    \"summed_metalcenter_descriptors\",\n",
    "    \"summed_functionalgroup_descriptors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = select_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[F].values\n",
    "y_train = df_train[[\"r\", \"g\", \"b\"]] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_dict = read_pickle(config[\"augmentation\"][\"augmentation_dict\"])\n",
    "df_train = augment_data(df_train, augment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[F].values\n",
    "y_train = df_train[[\"r\", \"g\", \"b\"]] / 255\n",
    "\n",
    "X_test = df_test[F].values\n",
    "y_test = df_test[[\"r\", \"g\", \"b\"]] / 255\n",
    "\n",
    "name_train = df_train[\"color_cleaned\"]\n",
    "name_test = df_test[\"color_cleaned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_valid, y_test, y_valid = train_test_split(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        train_size=0.9,\n",
    "        random_state=int(821996),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MinMaxScaler' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f3f0823146e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MinMaxScaler' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:colorml] *",
   "language": "python",
   "name": "conda-env-colorml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
